{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "# use bfloat16 for the entire notebook\n",
    "torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16).__enter__()\n",
    "\n",
    "if torch.cuda.get_device_properties(0).major >= 8:\n",
    "    # turn on tfloat32 for Ampere GPUs (https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices)\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    \n",
    "from sam2.build_sam import build_sam2_video_predictor\n",
    "\n",
    "sam2_checkpoint = \"./checkpoints/sam2_hiera_tiny.pt\"\n",
    "model_cfg = \"sam2_hiera_t.yaml\"\n",
    "\n",
    "predictor = build_sam2_video_predictor(model_cfg, sam2_checkpoint)\n",
    "\n",
    "def show_mask(mask, ax, obj_id=None, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        cmap = plt.get_cmap(\"tab20\")\n",
    "        cmap_idx = 0 if obj_id is None else obj_id\n",
    "        color = np.array([*cmap(cmap_idx)[:3], 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "def show_points(coords, labels, ax, marker_size=200):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `video_dir` a directory of JPEG frames with filenames like `<frame_index>.jpg`\n",
    "video_dir = \"/home/minqi/Desktop/ProBio/ProBio_final/valid/004/images\"\n",
    "\n",
    "# scan all the JPEG frame names in this directory\n",
    "frame_names = [\n",
    "    p for p in os.listdir(video_dir)\n",
    "    if os.path.splitext(p)[-1] in [\".jpg\", \".jpeg\", \".JPG\", \".JPEG\"]\n",
    "]\n",
    "frame_names.sort(key=lambda p: int(os.path.splitext(p)[0]))\n",
    "\n",
    "# take a look the first video frame\n",
    "# frame_idx = 0\n",
    "# plt.figure(figsize=(4, 3))\n",
    "# plt.title(f\"frame {frame_idx}\")\n",
    "# plt.imshow(Image.open(os.path.join(video_dir, frame_names[frame_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame loading (JPEG): 100%|██████████| 39/39 [00:00<00:00, 53.81it/s]\n"
     ]
    }
   ],
   "source": [
    "inference_state = predictor.init_state(video_path=video_dir)\n",
    "predictor.reset_state(inference_state)\n",
    "\n",
    "import json\n",
    "with open(os.path.join(video_dir, '../label.json'), \"rb\") as f:\n",
    "    label = json.load(f)\n",
    "    \n",
    "objects = {}\n",
    "for frame in label:\n",
    "    for item in frame['items']:\n",
    "        if item['object_id'] not in objects:\n",
    "            seg = item['segmentation']\n",
    "\n",
    "            from pycocotools import mask\n",
    "            import numpy as np\n",
    "            rle = mask.frPyObjects(seg, 480, 640)\n",
    "            binary_mask = mask.decode(rle)\n",
    "            if len(binary_mask.shape) == 3:\n",
    "                binary_mask = np.max(binary_mask, axis=2)\n",
    "            objects[item['object_id']] = {'first_frame': int(frame['path']), 'mask': binary_mask}\n",
    "    \n",
    "# import math\n",
    "# plt.figure(figsize=(4, 10))\n",
    "# a = int(math.sqrt(len(objects)))+1\n",
    "# fig,axes = plt.subplots(a,a,figsize=(4*a, 4*a))\n",
    "\n",
    "# for i,item in enumerate(objects):\n",
    "#     obj = objects[item]\n",
    "#     ann_frame_idx = obj['first_frame']  # the frame index we interact with\n",
    "#     ann_obj_id = item  # give a unique id to each object we interact with (it can be any integers)\n",
    "\n",
    "#     labels = np.array([1], np.int32)\n",
    "#     _, out_obj_ids, out_mask_logits = predictor.add_new_mask(\n",
    "#         inference_state=inference_state,\n",
    "#         frame_idx=ann_frame_idx,\n",
    "#         obj_id=ann_obj_id,\n",
    "#         mask=obj['mask']\n",
    "#     )\n",
    "\n",
    "#     # show the results on the current (interacted) frame\n",
    "#     axes[i//a][i%a].set_title(f\"frame {ann_frame_idx} Object {ann_obj_id}\")\n",
    "#     axes[i//a][i%a].imshow(Image.open(os.path.join(video_dir, frame_names[ann_frame_idx])))\n",
    "#     # show_points(points, labels,axes[i//a][i%a])\n",
    "#     show_mask((out_mask_logits[-1] > 0.0).cpu().numpy(), axes[i//a][i%a], obj_id=int(out_obj_ids[-1]))\n",
    "\n",
    "for i,item in enumerate(objects):\n",
    "    obj = objects[item]\n",
    "    ann_frame_idx = obj['first_frame']  # the frame index we interact with\n",
    "    ann_obj_id = int(item)  # give a unique id to each object we interact with (it can be any integers)\n",
    "\n",
    "    labels = np.array([1], np.int32)\n",
    "    _, out_obj_ids, out_mask_logits = predictor.add_new_mask(\n",
    "        inference_state=inference_state,\n",
    "        frame_idx=ann_frame_idx,\n",
    "        obj_id=ann_obj_id,\n",
    "        mask=obj['mask']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "propagate in video: 100%|██████████| 39/39 [00:07<00:00,  5.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# run propagation throughout the video and collect the results in a dict\n",
    "video_segments = {}  # video_segments contains the per-frame segmentation results\n",
    "for out_frame_idx, out_obj_ids, out_mask_logits in predictor.propagate_in_video(inference_state):\n",
    "    video_segments[out_frame_idx] = {\n",
    "        out_obj_id: (out_mask_logits[i] > 0.0).cpu().numpy()\n",
    "        for i, out_obj_id in enumerate(out_obj_ids)\n",
    "    }\n",
    "\n",
    "# render the segmentation results every few frames\n",
    "# vis_frame_stride = 2\n",
    "# plt.close(\"all\")\n",
    "# for out_frame_idx in range(0, len(frame_names), vis_frame_stride):\n",
    "#     plt.figure(figsize=(6, 4))\n",
    "#     plt.title(f\"frame {out_frame_idx}\")\n",
    "#     plt.imshow(Image.open(os.path.join(video_dir, frame_names[out_frame_idx])))\n",
    "#     for out_obj_id, out_mask in video_segments[out_frame_idx].items():\n",
    "#         show_mask(out_mask, plt.gca(), obj_id=out_obj_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "results_path = './results'\n",
    "file_name = '004_'\n",
    "\n",
    "def sam2_result_to_file(video_segments,file_name):\n",
    "    # 确保结果目录存在\n",
    "    os.makedirs(results_path, exist_ok=True)\n",
    "    \n",
    "    # 打开结果文件\n",
    "    with open(os.path.join(results_path, f'{file_name}.txt'), 'w') as f:\n",
    "        for frame,items in video_segments.items():\n",
    "            for item,mask in items.items():\n",
    "                # 计算掩码的边界框 (L, T, W, H)\n",
    "                mask = mask[0] # This is a 3D tensor, we only need the first channel\n",
    "                rows = np.any(mask, axis=1)\n",
    "                cols = np.any(mask, axis=0)\n",
    "                if rows.any():\n",
    "                    top, bottom = np.where(rows)[0][[0, -1]]\n",
    "                    left, right = np.where(cols)[0][[0, -1]]\n",
    "                    width = right - left + 1\n",
    "                    height = bottom - top + 1\n",
    "                else:\n",
    "                    top, left, width, height = 0, 0, 0, 0\n",
    "                f.write(f'{frame}, {item}, {left}, {top}, {width}, {height}, 1, -1, -1, -1\\n')\n",
    "\n",
    "sam2_result_to_file(video_segments, file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam2probio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
